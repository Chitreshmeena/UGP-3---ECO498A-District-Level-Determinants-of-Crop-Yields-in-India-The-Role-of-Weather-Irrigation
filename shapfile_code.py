# -*- coding: utf-8 -*-
"""Shapfile_codetemp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p1UvFo0vRlWlHHwkaZ27rq6wXsZZLAy3
"""

pip install geopandas pandas shapely

import pandas as pd
import geopandas as gpd
from shapely.geometry import Point

# ✅ Step 1: Load your temperature CSV file (from NASA POWER)
csv_path = r"/content/POWER_Regional_Monthly_1984_2017.csv"
df = pd.read_csv(csv_path, skiprows=10)  # Skip NASA POWER headers

# Preview your data (adjust column names if needed)
print(df.columns)

# ✅ Step 2: Convert to GeoDataFrame
# Rename columns if necessary
df.rename(columns={"LAT": "lat", "LON": "lon"}, inplace=True)

# Create Point geometry from lat/lon
geometry = [Point(xy) for xy in zip(df["lon"], df["lat"])]
gdf_temp = gpd.GeoDataFrame(df, geometry=geometry, crs="EPSG:4326")

# ✅ Step 3: Load the shapefile (district boundaries)
shapefile_path = r"/content/gadm41_IND_2.shp"
gdf_districts = gpd.read_file(shapefile_path)
gdf_districts = gdf_districts.to_crs("EPSG:4326")  # Ensure same CRS

# ✅ Step 4: Spatial join – assign each temperature point to a district
gdf_joined = gpd.sjoin(gdf_temp, gdf_districts, how="inner", predicate="within")

# ✅ Step 5: Group by district and date – compute average temperature
# Adjust depending on whether you have monthly or annual data
if "MO" in gdf_joined.columns:
    group_cols = ["NAME_1", "NAME_2", "YEAR", "MO"]  # Monthly
else:
    group_cols = ["NAME_1", "NAME_2", "YEAR"]        # Annual

result = (
    gdf_joined.groupby(group_cols)
    .agg(Mean_Temp=("T2M", "mean"))
    .reset_index()
)

# Rename for clarity
result.columns = ["State", "District", "Year", "Month", "Mean_Temp"] if "MO" in gdf_joined.columns else ["State", "District", "Year", "Mean_Temp"]

# ✅ Step 6: Save to CSV
result.to_csv("districtwise_temp_delhi.csv", index=False)

print("✅ District-wise temperature averages saved to 'districtwise_temp_delhi.csv'")

Index(['T2M', '1984', '29.0', '73.125', '12.89', '14.7', 26.06, ...])

import pandas as pd

# Skip NASA POWER metadata rows (usually first 10)
df = pd.read_csv(r"/content/POWER_Regional_Monthly_1984_2017.csv", skiprows=10)

# Show the actual column names
print(df.columns)

Index(['YEAR', 'MO', 'LAT', 'LON', 'T2M'], dtype='object')

from shapely.geometry import Point
import geopandas as gpd

# Rename columns to lowercase for easier handling
df.rename(columns={"LAT": "lat", "LON": "lon"}, inplace=True)

# Convert to GeoDataFrame using latitude and longitude
geometry = [Point(xy) for xy in zip(df["lon"], df["lat"])]
gdf_temp = gpd.GeoDataFrame(df, geometry=geometry, crs="EPSG:4326")

df.rename(columns={"LAT": "lat", "LON": "lon"}, inplace=True)
print(df.columns.tolist())

import pandas as pd

# Try skipping more rows (usually ~12)
df = pd.read_csv(r"/content/POWER_Regional_Monthly_1984_2017.csv", skiprows=9)

# Show the real columns now
print(df.columns.tolist())

import pandas as pd
import geopandas as gpd
from shapely.geometry import Point

# Step 1: Load the wide-format CSV
df = pd.read_csv("/content/POWER_Regional_Monthly_1984_2017.csv", skiprows=9)

# Step 2: Drop 'PARAMETER' column (just says 'T2M')
df.drop(columns=["PARAMETER"], inplace=True)

# Step 3: Melt from wide to long format
df_long = df.melt(
    id_vars=["YEAR", "LAT", "LON"],
    value_vars=["JAN", "FEB", "MAR", "APR", "MAY", "JUN", "JUL", "AUG", "SEP", "OCT", "NOV", "DEC"],
    var_name="Month",
    value_name="T2M"
)

# Step 4: Create geometry
geometry = [Point(xy) for xy in zip(df_long["LON"], df_long["LAT"])]
gdf_temp = gpd.GeoDataFrame(df_long, geometry=geometry, crs="EPSG:4326")

# Step 5: Load India district shapefile
gdf_districts = gpd.read_file("/content/gadm41ind2/gadm41_IND_2.shp").to_crs("EPSG:4326")

# Step 6: Spatial join
gdf_joined = gpd.sjoin(gdf_temp, gdf_districts, how="inner", predicate="within")

# Step 7: Group by district, year, and month
result = (
    gdf_joined.groupby(["NAME_1", "NAME_2", "YEAR", "Month"])
    .agg(Mean_Temp=("T2M", "mean"))
    .reset_index()
)

# Step 8: Save output
result.columns = ["State", "District", "Year", "Month", "Mean_Temp"]
result.to_csv("districtwise_monthly_temperature.csv", index=False)

print("✅ Saved as 'districtwise_monthly_temperature.csv'")

import pandas as pd
import geopandas as gpd
from shapely.geometry import Point

# Step 1: Load the new seasonal data CSV
df = pd.read_csv("/content/merged_climate_data.csv")  # Update path if needed

# Step 2: Create Point geometries from LAT/LON
geometry = [Point(xy) for xy in zip(df["LON"], df["LAT"])]
gdf = gpd.GeoDataFrame(df, geometry=geometry, crs="EPSG:4326")

# Step 3: Load India district shapefile
gdf_districts = gpd.read_file("/content/Shape files/gadm41_IND_2.shp").to_crs("EPSG:4326")

# Step 4: Spatial join to map points to districts
gdf_joined = gpd.sjoin(gdf, gdf_districts, how="inner", predicate="within")

# Step 5: Group by District, State, Year and compute mean of all four variables
result = (
    gdf_joined.groupby(["NAME_1", "NAME_2", "YEAR"])
    .agg({
        "Prec_Raviavg": "mean",
        "Prec_Kharifavg": "mean",
        "Temp_Raviavg": "mean",
        "Temp_Kharifavg": "mean"
    })
    .reset_index()
)

# Step 6: Rename columns for clarity
result.columns = ["State", "District", "Year", "Prec_Raviavg", "Prec_Kharifavg", "Temp_Raviavg", "Temp_Kharifavg"]

# Step 7: Save the result
result.to_csv("districtwise_seasonal_temp_precip.csv", index=False)

print("✅ File saved as 'districtwise_seasonal_temp_precip.csv'")



from google.colab import drive
drive.mount('/content/drive')